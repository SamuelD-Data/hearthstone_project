{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hearthstone Project\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "- Thoroughly prepare so that it is ready for exploration and modeling\n",
    "    - I won't be creating any models for this project but I'd still like to prepare the data nonetheless\n",
    "- Explore the data to gather insights about the characteristics of the game's different class types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establishing environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire\n",
    "Acquiring data from local csv files\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in card data and saving as DF\n",
    "cards = pd.read_csv('hearthstone_standard_cards.csv')\n",
    "\n",
    "# reading in card classes and saving as DF\n",
    "classes = pd.read_csv('classes.csv')\n",
    "\n",
    "# reading in minion types data and saving as DF\n",
    "mtypes = pd.read_csv('minionTypes.csv')\n",
    "\n",
    "# reading in rarities data and saving as DF\n",
    "rarities = pd.read_csv('rarities.csv')\n",
    "\n",
    "# reading in set groups data and saving as DF\n",
    "setgroups = pd.read_csv('setGroups.csv')\n",
    "\n",
    "# reading in card sets data and saving as DF\n",
    "sets = pd.read_csv('sets.csv')\n",
    "\n",
    "# reading in types data and saving as DF\n",
    "ctypes = pd.read_csv('types.csv')\n",
    "\n",
    "# reading in keywords data and saving as DF\n",
    "keywords = pd.read_csv('keywords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare\n",
    "Preparing data for exploration\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercasing all DF columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercasing cards DF columns\n",
    "cards.columns = cards.columns.str.lower()\n",
    "\n",
    "# lowercasing name and text column values\n",
    "cards.text = cards.text.str.lower()\n",
    "cards.name = cards.name.str.lower()\n",
    "\n",
    "# creating list of all DFs besides cards\n",
    "df_list = [classes, mtypes, rarities, setgroups, sets, ctypes, keywords]\n",
    "\n",
    "# iterating through DFs\n",
    "# lowercasing all column names, dropping original name column, renaming slug to name column\n",
    "for dtafrm in df_list:\n",
    "        dtafrm.columns = dtafrm.columns.str.lower()\n",
    "        dtafrm.drop(columns = 'name', inplace = True)\n",
    "        dtafrm.rename(columns = {\"slug\": \"name\"}, inplace = True)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 'classes' DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing brackets and commas from multiclassids column\n",
    "cards.multiclassids = cards.multiclassids.str.replace('\\]|,|\\[' , '')\n",
    "\n",
    "# creating column to hold primary class id \n",
    "# if card is of one class, this will reflect its sole class\n",
    "# if card is dual, this will reflect the 1st of the two classes in the multiClassIds column\n",
    "# necessary since dual class cards erroneously hold the 'neutral' class value in their primary class id \n",
    "cards['primeclassid'] = np.where((cards.multiclassids.str.contains(' ')), cards[\"multiclassids\"].str.split(\" \", expand = True)[0], cards.classid)\n",
    "\n",
    "# converting key columns to make all value data types match\n",
    "cards.primeclassid = cards.primeclassid.astype(str)\n",
    "classes.id = classes.id.astype(str)\n",
    "\n",
    "# merging 'classes' df with card df\n",
    "df = pd.merge(cards, classes[['id', 'name']], \n",
    "              left_on = 'primeclassid', right_on = 'id', how=\"left\", \n",
    "              suffixes = (None, '_prime_hero_class'))\n",
    "\n",
    "# dropping columns I no longer need\n",
    "df.drop(columns = ['primeclassid', 'classid'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 'mtypes' DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# changing null values of minionTypeId for neutral minions to -1\n",
    "df['miniontypeid'] = np.where((df.miniontypeid.isnull() == True) & (df.cardtypeid == 4), -1, df.miniontypeid)\n",
    "\n",
    "# adding missing keyword data to 'keywords' df\n",
    "# -1 is for minions with no tribe\n",
    "mtypes.loc[len(mtypes.index)] = ['no tribe', -1]\n",
    "\n",
    "# merging 'mtypes' df\n",
    "df = pd.merge(df, mtypes[['id', 'name']], \n",
    "              left_on = 'miniontypeid', right_on = 'id', how=\"left\", \n",
    "              suffixes = (None, '_minion_type'))\n",
    "\n",
    "# dropping column I no longer need\n",
    "df.drop(columns = ['miniontypeid'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 'rarities' DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging 'rarities' df\n",
    "df = pd.merge(df, rarities[['id', 'name']], \n",
    "              left_on = 'rarityid', right_on = 'id', how=\"left\", \n",
    "              suffixes = (None, '_rarity'))\n",
    "\n",
    "# dropping column I no longer need\n",
    "df.drop(columns = ['rarityid'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 'setGroups' DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging 'setgroups' df\n",
    "df = pd.merge(df, sets[['id', 'name']], \n",
    "              left_on = 'cardsetid', right_on = 'id', how=\"left\", \n",
    "              suffixes = (None, '_set'))\n",
    "\n",
    "# dropping column I no longer need\n",
    "df.drop(columns = ['cardsetid'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 'ctypes' DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging 'ctypes' df\n",
    "df = pd.merge(df, ctypes[['id', 'name']], \n",
    "              left_on = 'cardtypeid', right_on = 'id', how=\"left\", \n",
    "              suffixes = (None, '_card_type'))\n",
    "\n",
    "# dropping column I no longer need\n",
    "df.drop(columns = ['cardtypeid'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 'keywords' DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adding missing keyword data to 'keywords' df\n",
    "keywords.loc[len(keywords.index)] = ['64', 'start-of-game', \n",
    "                                     'does something at the start of the game.', \n",
    "                                     'does something at the start of the game.']\n",
    "\n",
    "# removing brackets and commas from keyword id column\n",
    "df.keywordids = df.keywordids.str.replace('\\]|,|\\[' , '')\n",
    "\n",
    "# splitting keyword ids into separate columns for each card\n",
    "kwdf = df[\"keywordids\"].str.split(\" \", expand = True) \n",
    "\n",
    "# renaming columns\n",
    "kwdf.columns = ['keywordid1', 'keywordid2', 'keywordid3', 'keywordid4', 'keywordid5']\n",
    "\n",
    "# concatenating split keyword id columns with main df\n",
    "df = pd.concat([df, kwdf], axis=1)\n",
    "\n",
    "# converting keywords id column to str type to enable merge\n",
    "keywords.id = keywords.id.astype(str)\n",
    "\n",
    "# creating loop to add a column for the text name of each keyword ability of each card\n",
    "# via merging with keywords DF\n",
    "for x in kwdf.columns:\n",
    "    df = pd.merge(df, keywords[['id', 'name']], \n",
    "              left_on = x, right_on = 'id', how = \"left\",\n",
    "              suffixes = (None, x + '_name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1289, 44)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking number of rows in current DF\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1289, 44)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of rows if duplicates were dropped\n",
    "df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No duplicates found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for proper data types, categorical columns (based on domain knowledge), and null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1289 entries, 0 to 1288\n",
      "Data columns (total 44 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     1289 non-null   int64  \n",
      " 1   collectible            1289 non-null   int64  \n",
      " 2   slug                   1289 non-null   object \n",
      " 3   multiclassids          1289 non-null   object \n",
      " 4   artistname             1288 non-null   object \n",
      " 5   manacost               1289 non-null   int64  \n",
      " 6   name                   1289 non-null   object \n",
      " 7   text                   1271 non-null   object \n",
      " 8   image                  1289 non-null   object \n",
      " 9   imagegold              805 non-null    object \n",
      " 10  flavortext             1289 non-null   object \n",
      " 11  cropimage              1289 non-null   object \n",
      " 12  duels                  708 non-null    object \n",
      " 13  health                 825 non-null    float64\n",
      " 14  attack                 860 non-null    float64\n",
      " 15  keywordids             877 non-null    object \n",
      " 16  childids               295 non-null    object \n",
      " 17  durability             48 non-null     float64\n",
      " 18  armor                  6 non-null      float64\n",
      " 19  id_prime_hero_class    1289 non-null   object \n",
      " 20  name_prime_hero_class  1289 non-null   object \n",
      " 21  id_minion_type         818 non-null    float64\n",
      " 22  name_minion_type       818 non-null    object \n",
      " 23  id_rarity              1289 non-null   int64  \n",
      " 24  name_rarity            1289 non-null   object \n",
      " 25  id_set                 1289 non-null   int64  \n",
      " 26  name_set               1289 non-null   object \n",
      " 27  id_card_type           1289 non-null   int64  \n",
      " 28  name_card_type         1289 non-null   object \n",
      " 29  keywordid1             877 non-null    object \n",
      " 30  keywordid2             285 non-null    object \n",
      " 31  keywordid3             34 non-null     object \n",
      " 32  keywordid4             4 non-null      object \n",
      " 33  keywordid5             2 non-null      object \n",
      " 34  idkeywordid1_name      871 non-null    object \n",
      " 35  namekeywordid1_name    871 non-null    object \n",
      " 36  idkeywordid2_name      282 non-null    object \n",
      " 37  namekeywordid2_name    282 non-null    object \n",
      " 38  idkeywordid3_name      34 non-null     object \n",
      " 39  namekeywordid3_name    34 non-null     object \n",
      " 40  idkeywordid4_name      4 non-null      object \n",
      " 41  namekeywordid4_name    4 non-null      object \n",
      " 42  idkeywordid5_name      2 non-null      object \n",
      " 43  namekeywordid5_name    2 non-null      object \n",
      "dtypes: float64(5), int64(6), object(33)\n",
      "memory usage: 453.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following columns will be dropped as they won't be needed for the expected operations of this project\n",
    "    - id, slug\n",
    "        - unique identifiers for cards, not needed since the 'name' column provides this while also being easier to reference\n",
    "    - artistname, image, imagegold, cropimage\n",
    "        - I won't be exploring images or artist names in this iteration of the project\n",
    "    - collectible\n",
    "        - Only 1 value, no nulls, doesn't distinguish any cards\n",
    "    - all columns reflecting key words with the exception of the boolean columns and the 'slug_keyword#_name' columns\n",
    "        - The exempted columns are sufficient for the project's expected operations\n",
    "     \n",
    "     \n",
    "- Based on my domain knowledge of the game, I'm inferring that several of the columns are categorical\n",
    "    - I need to create boolean columns for categorical columns (rarity, card set, etc.)\n",
    "\n",
    "\n",
    "- Many null values that need to be addressed\n",
    "    - text\n",
    "    - duels\n",
    "    - minion type id\n",
    "    - health\n",
    "    - attack\n",
    "    - child ids\n",
    "    - durability\n",
    "    - armor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping columns that aren't needed for the planned operations of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating list of columns to drop\n",
    "columns_to_drop = ['id', 'slug', 'artistname', 'image', 'imagegold', 'flavortext', 'cropimage', 'collectible']\n",
    "\n",
    "# dropping columns\n",
    "df.drop(columns = columns_to_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing nulls in 'text' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                                                                18\n",
       "<b>taunt</b>                                                       15\n",
       "<b>charge</b>                                                       7\n",
       "<b>stealth</b>                                                      6\n",
       "<b>spell damage +1</b>                                              6\n",
       "                                                                   ..\n",
       "<b>choose one -</b> draw a card; or restore 5 health.               1\n",
       "<b>lifesteal</b>, <b>rush</b>, <b>windfury</b>                      1\n",
       "<b>battlecry:</b> give a friendly beast +2/+2 and <b>taunt</b>.     1\n",
       "give your hero +8&nbsp;attack this turn.                            1\n",
       "summon copies of enemy minions. they attack their copies.           1\n",
       "Name: text, Length: 1215, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking values in text box\n",
    "df.text.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling null text values with 'no effect'\n",
    "df[\"text\"].fillna(\"no effect\", inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing nulls in 'duels' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relevant': True, 'constructed': True}    708\n",
       "NaN                                        581\n",
       "Name: duels, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking duels values\n",
    "df.duels.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating duels column so that cards that were allowed in duels have value of 1 and 0 otherwise\n",
    "df['duels'] = np.where((df.duels == \"{'relevant': True, 'constructed': True}\"), 1, 0)\n",
    "\n",
    "df.rename(columns={'duels':'in_duels'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing nulls in 'id_minion_type', and 'slug_minion_type' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0     497\n",
       " NaN     471\n",
       " 20.0     75\n",
       " 15.0     63\n",
       " 18.0     51\n",
       " 24.0     50\n",
       " 17.0     32\n",
       " 14.0     25\n",
       " 23.0     18\n",
       " 21.0      6\n",
       " 26.0      1\n",
       "Name: id_minion_type, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking minontypeId values\n",
    "df.id_minion_type.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting nulls, aka non-minion cards to 'not a minion' type\n",
    "df['id_minion_tribe'] = np.where((df.id_minion_type.isnull() == True), 'not a minion', df.id_minion_type)\n",
    "df['name_minion_tribe'] = np.where((df.name_minion_type.isnull() == True), 'not a minion', df.name_minion_type)\n",
    "\n",
    "# dropping minionTypeId since id_minion_type suffices\n",
    "df.drop(columns = ['id_minion_type', 'name_minion_type'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing nulls in 'childIds' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                                                                       994\n",
       "[52897, 52900, 53160, 53161, 53162, 53163, 55378, 60588, 64652, 64653]     15\n",
       "[59723]                                                                     8\n",
       "[56927]                                                                     3\n",
       "[53921]                                                                     3\n",
       "                                                                         ... \n",
       "[60, 812, 835]                                                              1\n",
       "[53442]                                                                     1\n",
       "[1715]                                                                      1\n",
       "[53412]                                                                     1\n",
       "[847, 57936]                                                                1\n",
       "Name: childids, Length: 261, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking childIds values\n",
    "df.childids.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling nulls with \"no_childid\"\n",
    "df.childids.fillna(\"no_childid\", inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing nulls in 'health', 'attack', 'durability', and 'armor' columns\n",
    "All of these variables respective columns have null values since none of these variables apply to every card (examples: only minions have health while only weapons have durability). For the time being I'll fill these nulls \n",
    "with a value that represents infinity. The benefit of this method is that it allows me to fill the nulls while preserving the int64 data type of the column. Furthermore, no matter what value blizzard assigns to these variables in future cards, this value probably wouldn't be used. If this causes issues later I'll employ a different means of handling them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of column names\n",
    "hada = ['health', 'attack', 'durability', 'armor']\n",
    "\n",
    "# iterating through columns filling nulls within each\n",
    "for att in hada:\n",
    "    df[att].fillna(float('inf'), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating boolean columns for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boolean columns for 'keywords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop iterates through each keyword and creates a boolean column for it\n",
    "for kw in keywords.name:\n",
    "    df['has_' + kw] = np.where(\n",
    "    (df.namekeywordid1_name == kw) |\n",
    "    (df.namekeywordid2_name == kw) |\n",
    "    (df.namekeywordid3_name == kw) |\n",
    "    (df.namekeywordid4_name == kw) |\n",
    "    (df.namekeywordid5_name == kw), 1, 0)\n",
    "    \n",
    "# creating empty list\n",
    "key_word_col_drop = []\n",
    "\n",
    "# iterating through columns in df and creating list of columns to drop\n",
    "for col in df.columns:\n",
    "    if 'keywordid' in col:\n",
    "        key_word_col_drop.append(col)\n",
    "        \n",
    "# dropping columns\n",
    "df.drop(columns = key_word_col_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boolean columns for 'hero classes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing brackets and commas from multiclassids column\n",
    "df.multiclassids = df.multiclassids.str.replace('\\]|,|\\[' , '')\n",
    "\n",
    "# creating column that holds secondary class separate from primary class\n",
    "df['id_second_hero_class'] = df[\"multiclassids\"].str.split(\" \", expand = True)[1]\n",
    "\n",
    "# converting column to str type to enable merge with newly created column 'id_second_hero_class'\n",
    "classes.id = classes.id.astype(str)\n",
    "\n",
    "# creating df containing columns for merge in order to rename before merge without altering original classes DF\n",
    "classes2 = classes[['id', 'name']]\n",
    "\n",
    "# renaming columns\n",
    "classes2.columns = ['id_second_hero_class', 'name_second_hero_class']\n",
    "\n",
    "# merging 'classes' on secondary hero class id to get secondary class names\n",
    "df = pd.merge(df, classes2[['id_second_hero_class', 'name_second_hero_class']], \n",
    "              on = 'id_second_hero_class', how = \"left\")\n",
    "\n",
    "# creating boolean columns for each hero class\n",
    "for c in classes.name:\n",
    "    df['is_' + c] = np.where(\n",
    "    (df.name_prime_hero_class == c) | (df.name_second_hero_class == c), 1, 0)\n",
    "\n",
    "# filling nulls in new columns\n",
    "df['name_second_hero_class'].fillna('monoclass', inplace = True)\n",
    "df['id_second_hero_class'].fillna('monoclass', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boolean column for multiclass cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating column where 1 = multiclass, 0 = monoclass)\n",
    "# contains ' ' will suffice since only cards with a space in this value are multiclass\n",
    "df['is_multiclass'] = np.where((df.multiclassids.str.contains(' ')), 1, 0)\n",
    "\n",
    "# dropping column I no longer need\n",
    "df.drop(columns = 'multiclassids', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boolean column for cards with child ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating column where 1 = card has childids, 0 = card has no childids)\n",
    "# contains ',' will suffice since only cards with a comma in this value have childids\n",
    "df['has_child_ids'] = np.where((df.childids.str.contains(',')), 1, 0)\n",
    "\n",
    "# dropping column I no longer need\n",
    "df.drop(columns = 'childids', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boolean columns for rarity levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating through levels of rarity (common, rare, epic, etc)\n",
    "# creating boolean column for each\n",
    "for level in rarities.name:\n",
    "    df['is_' + level] = np.where((df.name_rarity == level), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boolean columns for card sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# iterating through set names and creating a boolean column for each\n",
    "for setname in sets.name:\n",
    "    df['is_' + setname] = np.where((df.name_set == setname), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boolean columns for card type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating through card types and creating a boolean column for each\n",
    "for ctype in ctypes.name:\n",
    "    df['is_' + ctype] = np.where((df.name_card_type == ctype), 1, 0)\n",
    "\n",
    "# dropping column I no longer need\n",
    "df.drop(columns = 'id_card_type', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boolean columns for minion tribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating through minion tribes and creating a boolean column for each\n",
    "for mtype in mtypes.name:\n",
    "    df['is_' + mtype] = np.where((df.name_minion_tribe == mtype), 1, 0)\n",
    "\n",
    "# dropping column I no longer need\n",
    "df.drop(columns = 'id_minion_tribe', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping boolean columns with all 0 values\n",
    "I know that some of the sets and keywords that were turned into booleans are not currently in standard (the format the collection of the cards in the data are part of). These columns will be completely filled with 0s so I'm going to drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of index values for columns that only have 0 values\n",
    "all_0_cols = np.where(df.isin([0]).all() == True)\n",
    "\n",
    "# dropping columns based on index value\n",
    "df.drop(df.columns[all_0_cols], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting column order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting order of columns\n",
    "df = df[['manacost', 'name', 'text', 'in_duels', 'has_child_ids', 'health', 'attack',\n",
    "       'durability', 'armor', 'id_prime_hero_class', 'name_prime_hero_class', \n",
    "       'id_second_hero_class', 'name_second_hero_class',\n",
    "       'id_rarity', 'name_rarity', 'id_set', 'name_set', 'name_card_type',\n",
    "       'name_minion_tribe', 'has_taunt', 'has_spellpower', 'has_divine-shield',\n",
    "       'has_charge', 'has_secret', 'has_stealth', 'has_battlecry',\n",
    "       'has_freeze', 'has_windfury', 'has_deathrattle', 'has_combo',\n",
    "       'has_overload', 'has_silence', 'has_counter', 'has_immune',\n",
    "       'has_discover', 'has_quest', 'has_poisonous', 'has_lifesteal',\n",
    "       'has_rush', 'has_evilzug', 'has_twinspell', 'has_mega-windfury',\n",
    "       'has_reborn', 'has_empower', 'has_outcast', 'has_spellburst',\n",
    "       'has_sidequest', 'has_corrupt', 'has_start-of-game',\n",
    "       'is_demonhunter', 'is_druid', 'is_hunter', 'is_mage', 'is_paladin', 'is_priest',\n",
    "       'is_rogue', 'is_shaman', 'is_warlock', 'is_warrior', 'is_neutral',\n",
    "       'is_multiclass', 'is_common', 'is_free', 'is_rare',\n",
    "       'is_epic', 'is_legendary', 'is_madness-at-the-darkmoon-faire',\n",
    "       'is_scholomance-academy', 'is_demonhunter-initiate',\n",
    "       'is_ashes-of-outland', 'is_galakronds-awakening',\n",
    "       'is_descent-of-dragons', 'is_saviors-of-uldum', 'is_rise-of-shadows',\n",
    "       'is_classic', 'is_basic', 'is_hero', 'is_minion', 'is_spell',\n",
    "       'is_weapon', 'is_murloc', 'is_demon', 'is_mech', 'is_elemental',\n",
    "       'is_beast', 'is_totem', 'is_pirate', 'is_dragon', 'is_all',\n",
    "       'is_no tribe']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
