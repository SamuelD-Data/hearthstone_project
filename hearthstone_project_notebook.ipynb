{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hearthstone Project\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "- Thoroughly prepare so that it is ready for exploration and modeling\n",
    "    - I won't be creating any models for this project but I'd still like to prepare the data nonetheless\n",
    "- Explore the data to gather insights about the characteristics of the game's different class types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establishing environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire\n",
    "Acquiring data from local csv files\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in card data and saving as DF\n",
    "cards = pd.read_csv('hearthstone_standard_cards.csv')\n",
    "\n",
    "# reading in card classes and saving as DF\n",
    "classes = pd.read_csv('classes.csv')\n",
    "\n",
    "# reading in minion types data and saving as DF\n",
    "mtypes = pd.read_csv('minionTypes.csv')\n",
    "\n",
    "# reading in rarities data and saving as DF\n",
    "rarities = pd.read_csv('rarities.csv')\n",
    "\n",
    "# reading in set groups data and saving as DF\n",
    "setgroups = pd.read_csv('setGroups.csv')\n",
    "\n",
    "# reading in card sets data and saving as DF\n",
    "sets = pd.read_csv('sets.csv')\n",
    "\n",
    "# reading in types data and saving as DF\n",
    "ctypes = pd.read_csv('types.csv')\n",
    "\n",
    "# reading in keywords data and saving as DF\n",
    "keywords = pd.read_csv('keywords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare\n",
    "Preparing data for exploration\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercasing all DF columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercasing cards DF columns\n",
    "cards.columns = cards.columns.str.lower()\n",
    "\n",
    "# lowercasing name and text column values\n",
    "cards.text = cards.text.str.lower()\n",
    "cards.name = cards.name.str.lower()\n",
    "\n",
    "# creating list of all DFs besides cards\n",
    "df_list = [classes, mtypes, rarities, setgroups, sets, ctypes, keywords]\n",
    "\n",
    "# iterating through DFs\n",
    "# lowercasing all column names, dropping original name column, renaming slug to name column\n",
    "for dtafrm in df_list:\n",
    "        dtafrm.columns = dtafrm.columns.str.lower()\n",
    "        dtafrm.drop(columns = 'name', inplace = True)\n",
    "        dtafrm.rename(columns = {\"slug\": \"name\"}, inplace = True)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 'classes' DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing brackets and commas from multiclassids column\n",
    "cards.multiclassids = cards.multiclassids.str.replace('\\]|,|\\[' , '')\n",
    "\n",
    "# creating column to hold primary class id \n",
    "# if card is of one class, this will reflect its sole class\n",
    "# if card is dual, this will reflect the 1st of the two classes in the multiClassIds column\n",
    "# necessary since dual class cards erroneously hold the 'neutral' class value in their primary class id \n",
    "cards['primeclassid'] = np.where((cards.multiclassids.str.contains(' ')), cards[\"multiclassids\"].str.split(\" \", expand = True)[0], cards.classid)\n",
    "\n",
    "# converting key columns to make all value data types match\n",
    "cards.primeclassid = cards.primeclassid.astype(str)\n",
    "classes.id = classes.id.astype(str)\n",
    "\n",
    "# merging 'classes' df with card df\n",
    "df = pd.merge(cards, classes[['id', 'name']], \n",
    "              left_on = 'primeclassid', right_on = 'id', how=\"left\", \n",
    "              suffixes = (None, '_prime_hero_class'))\n",
    "\n",
    "# dropping columns I no longer need\n",
    "df.drop(columns = ['primeclassid', 'classid'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 'mtypes' DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# changing null values of minionTypeId for neutral minions to -1\n",
    "df['miniontypeid'] = np.where((df.miniontypeid.isnull() == True) & (df.cardtypeid == 4), -1, df.miniontypeid)\n",
    "\n",
    "# adding missing keyword data to 'keywords' df\n",
    "# -1 is for minions with no tribe\n",
    "mtypes.loc[len(mtypes.index)] = ['no tribe', -1]\n",
    "\n",
    "# merging 'mtypes' df\n",
    "df = pd.merge(df, mtypes[['id', 'name']], \n",
    "              left_on = 'miniontypeid', right_on = 'id', how=\"left\", \n",
    "              suffixes = (None, '_minion_type'))\n",
    "\n",
    "# dropping column I no longer need\n",
    "df.drop(columns = ['miniontypeid'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 'rarities' DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging 'rarities' df\n",
    "df = pd.merge(df, rarities[['id', 'name']], \n",
    "              left_on = 'rarityid', right_on = 'id', how=\"left\", \n",
    "              suffixes = (None, '_rarity'))\n",
    "\n",
    "# dropping column I no longer need\n",
    "df.drop(columns = ['rarityid'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 'setGroups' DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging 'setgroups' df\n",
    "df = pd.merge(df, sets[['id', 'name']], \n",
    "              left_on = 'cardsetid', right_on = 'id', how=\"left\", \n",
    "              suffixes = (None, '_set'))\n",
    "\n",
    "# dropping column I no longer need\n",
    "df.drop(columns = ['cardsetid'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 'ctypes' DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging 'ctypes' df\n",
    "df = pd.merge(df, ctypes[['id', 'name']], \n",
    "              left_on = 'cardtypeid', right_on = 'id', how=\"left\", \n",
    "              suffixes = (None, '_card_type'))\n",
    "\n",
    "# dropping column I no longer need\n",
    "df.drop(columns = ['cardtypeid'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging 'keywords' DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adding missing keyword data to 'keywords' df\n",
    "keywords.loc[len(keywords.index)] = ['64', 'start-of-game', \n",
    "                                     'does something at the start of the game.', \n",
    "                                     'does something at the start of the game.']\n",
    "\n",
    "# removing brackets and commas from keyword id column\n",
    "df.keywordids = df.keywordids.str.replace('\\]|,|\\[' , '')\n",
    "\n",
    "# splitting keyword ids into separate columns for each card\n",
    "kwdf = df[\"keywordids\"].str.split(\" \", expand = True) \n",
    "\n",
    "# renaming columns\n",
    "kwdf.columns = ['keywordid1', 'keywordid2', 'keywordid3', 'keywordid4', 'keywordid5']\n",
    "\n",
    "# concatenating split keyword id columns with main df\n",
    "df = pd.concat([df, kwdf], axis=1)\n",
    "\n",
    "# converting keywords id column to str type to enable merge\n",
    "keywords.id = keywords.id.astype(str)\n",
    "\n",
    "# creating loop to add a column for the text name of each keyword ability of each card\n",
    "# via merging with keywords DF\n",
    "for x in kwdf.columns:\n",
    "    df = pd.merge(df, keywords[['id', 'name']], \n",
    "              left_on = x, right_on = 'id', how = \"left\",\n",
    "              suffixes = (None, x + '_name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1289, 44)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking number of rows in current DF\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1289, 44)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of rows if duplicates were dropped\n",
    "df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No duplicates found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for proper data types, categorical columns (based on domain knowledge), and null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1289 entries, 0 to 1288\n",
      "Data columns (total 44 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     1289 non-null   int64  \n",
      " 1   collectible            1289 non-null   int64  \n",
      " 2   slug                   1289 non-null   object \n",
      " 3   multiclassids          1289 non-null   object \n",
      " 4   artistname             1288 non-null   object \n",
      " 5   manacost               1289 non-null   int64  \n",
      " 6   name                   1289 non-null   object \n",
      " 7   text                   1271 non-null   object \n",
      " 8   image                  1289 non-null   object \n",
      " 9   imagegold              805 non-null    object \n",
      " 10  flavortext             1289 non-null   object \n",
      " 11  cropimage              1289 non-null   object \n",
      " 12  duels                  708 non-null    object \n",
      " 13  health                 825 non-null    float64\n",
      " 14  attack                 860 non-null    float64\n",
      " 15  keywordids             877 non-null    object \n",
      " 16  childids               295 non-null    object \n",
      " 17  durability             48 non-null     float64\n",
      " 18  armor                  6 non-null      float64\n",
      " 19  id_prime_hero_class    1289 non-null   object \n",
      " 20  name_prime_hero_class  1289 non-null   object \n",
      " 21  id_minion_type         818 non-null    float64\n",
      " 22  name_minion_type       818 non-null    object \n",
      " 23  id_rarity              1289 non-null   int64  \n",
      " 24  name_rarity            1289 non-null   object \n",
      " 25  id_set                 1289 non-null   int64  \n",
      " 26  name_set               1289 non-null   object \n",
      " 27  id_card_type           1289 non-null   int64  \n",
      " 28  name_card_type         1289 non-null   object \n",
      " 29  keywordid1             877 non-null    object \n",
      " 30  keywordid2             285 non-null    object \n",
      " 31  keywordid3             34 non-null     object \n",
      " 32  keywordid4             4 non-null      object \n",
      " 33  keywordid5             2 non-null      object \n",
      " 34  idkeywordid1_name      871 non-null    object \n",
      " 35  namekeywordid1_name    871 non-null    object \n",
      " 36  idkeywordid2_name      282 non-null    object \n",
      " 37  namekeywordid2_name    282 non-null    object \n",
      " 38  idkeywordid3_name      34 non-null     object \n",
      " 39  namekeywordid3_name    34 non-null     object \n",
      " 40  idkeywordid4_name      4 non-null      object \n",
      " 41  namekeywordid4_name    4 non-null      object \n",
      " 42  idkeywordid5_name      2 non-null      object \n",
      " 43  namekeywordid5_name    2 non-null      object \n",
      "dtypes: float64(5), int64(6), object(33)\n",
      "memory usage: 453.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following columns will be dropped as they won't be needed for the expected operations of this project\n",
    "    - id, slug\n",
    "        - unique identifiers for cards, not needed since the 'name' column provides this while also being easier to reference\n",
    "    - artistname, image, imagegold, cropimage\n",
    "        - I won't be exploring images or artist names in this iteration of the project\n",
    "    - collectible\n",
    "        - Only 1 value, no nulls, doesn't distinguish any cards\n",
    "    - all columns reflecting key words with the exception of the boolean columns and the 'slug_keyword#_name' columns\n",
    "        - The exempted columns are sufficient for the project's expected operations\n",
    "     \n",
    "     \n",
    "- Based on my domain knowledge of the game, I'm inferring that several of the columns are categorical\n",
    "    - I need to create boolean columns for categorical columns (rarity, card set, etc.)\n",
    "\n",
    "\n",
    "- Many null values that need to be addressed\n",
    "    - text\n",
    "    - duels\n",
    "    - minion type id\n",
    "    - health\n",
    "    - attack\n",
    "    - child ids\n",
    "    - durability\n",
    "    - armor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping columns that aren't needed for the planned operations of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating list of columns to drop\n",
    "columns_to_drop = ['id', 'slug', 'artistname', 'image', 'imagegold', 'flavortext', 'cropimage', 'collectible']\n",
    "\n",
    "# dropping columns\n",
    "df.drop(columns = columns_to_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing nulls in 'text' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                                                                                                     18\n",
       "<b>taunt</b>                                                                                            15\n",
       "<b>charge</b>                                                                                            7\n",
       "<b>stealth</b>                                                                                           6\n",
       "<b>spell damage +1</b>                                                                                   6\n",
       "                                                                                                        ..\n",
       "<b>battlecry:</b> <b>discover</b> a spell from another class.                                            1\n",
       "after your hero attacks, <b>discover</b> a <b>secret</b> and cast it.                                    1\n",
       "<b><b>spellburst</b>:</b> cast a random spell of the same cost.                                          1\n",
       "<b>battlecry:</b> give all dragons in your hand +3/+3.                                                   1\n",
       "<b>secret:</b> at the end of your opponent's turn, add copies of the cards they played to your hand.     1\n",
       "Name: text, Length: 1215, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking values in text box\n",
    "df.text.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling null text values with 'no effect'\n",
    "df[\"text\"].fillna(\"no effect\", inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing nulls in 'duels' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relevant': True, 'constructed': True}    708\n",
       "NaN                                        581\n",
       "Name: duels, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking duels values\n",
    "df.duels.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating duels column so that cards that were allowed in duels have value of 1 and 0 otherwise\n",
    "df['duels'] = np.where((df.duels == \"{'relevant': True, 'constructed': True}\"), 1, 0)\n",
    "\n",
    "df.rename(columns={'duels':'in_duels'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing nulls in 'id_minion_type', and 'slug_minion_type' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0     497\n",
       " NaN     471\n",
       " 20.0     75\n",
       " 15.0     63\n",
       " 18.0     51\n",
       " 24.0     50\n",
       " 17.0     32\n",
       " 14.0     25\n",
       " 23.0     18\n",
       " 21.0      6\n",
       " 26.0      1\n",
       "Name: id_minion_type, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking minontypeId values\n",
    "df.id_minion_type.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting nulls, aka non-minion cards to 'not a minion' type\n",
    "df['id_minion_tribe'] = np.where((df.id_minion_type.isnull() == True), 'not a minion', df.id_minion_type)\n",
    "df['name_minion_tribe'] = np.where((df.name_minion_type.isnull() == True), 'not a minion', df.name_minion_type)\n",
    "\n",
    "# dropping minionTypeId since id_minion_type suffices\n",
    "df.drop(columns = ['id_minion_type', 'name_minion_type'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing nulls in 'childIds' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                                                                       994\n",
       "[52897, 52900, 53160, 53161, 53162, 53163, 55378, 60588, 64652, 64653]     15\n",
       "[59723]                                                                     8\n",
       "[56927]                                                                     3\n",
       "[53921]                                                                     3\n",
       "                                                                         ... \n",
       "[61583]                                                                     1\n",
       "[60279]                                                                     1\n",
       "[56164, 56165, 56167, 56168, 56169, 56170, 56171, 56173, 56175]             1\n",
       "[61981]                                                                     1\n",
       "[56626, 56656, 56718, 57155, 57156, 57172, 57478, 57631, 57782]             1\n",
       "Name: childids, Length: 261, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking childIds values\n",
    "df.childids.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling nulls with \"no_childid\"\n",
    "df.childids.fillna(\"no_childid\", inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing nulls in 'health', 'attack', 'durability', and 'armor' columns\n",
    "All of these variables respective columns have null values since none of these variables apply to every card (examples: only minions have health while only weapons have durability). For the time being I'll fill these nulls \n",
    "with a value that represents infinity. The benefit of this method is that it allows me to fill the nulls while preserving the int64 data type of the column. Furthermore, no matter what value blizzard assigns to these variables in future cards, this value probably wouldn't be used. If this causes issues later I'll employ a different means of handling them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of column names\n",
    "hada = ['health', 'attack', 'durability', 'armor']\n",
    "\n",
    "# iterating through columns filling nulls within each\n",
    "for att in hada:\n",
    "    df[att].fillna(float('inf'), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating boolean columns for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boolean columns for 'keywords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop iterates through each keyword and creates a boolean column for it\n",
    "for kw in keywords.name:\n",
    "    df['has_' + kw] = np.where(\n",
    "    (df.namekeywordid1_name == kw) |\n",
    "    (df.namekeywordid2_name == kw) |\n",
    "    (df.namekeywordid3_name == kw) |\n",
    "    (df.namekeywordid4_name == kw) |\n",
    "    (df.namekeywordid5_name == kw), 1, 0)\n",
    "    \n",
    "# creating empty list\n",
    "key_word_col_drop = []\n",
    "\n",
    "# iterating through columns in df and creating list of columns to drop\n",
    "for col in df.columns:\n",
    "    if 'keywordid' in col:\n",
    "        key_word_col_drop.append(col)\n",
    "        \n",
    "# dropping columns\n",
    "df.drop(columns = key_word_col_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boolean columns for 'hero classes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing brackets and commas from multiclassids column\n",
    "df.multiclassids = df.multiclassids.str.replace('\\]|,|\\[' , '')\n",
    "\n",
    "# creating column that holds secondary class separate from primary class\n",
    "df['id_second_hero_class'] = df[\"multiclassids\"].str.split(\" \", expand = True)[1]\n",
    "\n",
    "# converting column to str type to enable merge with newly created column 'id_second_hero_class'\n",
    "classes.id = classes.id.astype(str)\n",
    "\n",
    "# creating df containing columns for merge in order to rename before merge without altering original classes DF\n",
    "classes2 = classes[['id', 'name']]\n",
    "\n",
    "# renaming columns\n",
    "classes2.columns = ['id_second_hero_class', 'name_second_hero_class']\n",
    "\n",
    "# merging 'classes' on secondary hero class id to get secondary class names\n",
    "df = pd.merge(df, classes2[['id_second_hero_class', 'name_second_hero_class']], \n",
    "              on = 'id_second_hero_class', how = \"left\")\n",
    "\n",
    "# creating boolean columns for each hero class\n",
    "for c in classes.name:\n",
    "    df['is_' + c] = np.where(\n",
    "    (df.name_prime_hero_class == c) | (df.name_second_hero_class == c), 1, 0)\n",
    "\n",
    "# filling nulls in new columns\n",
    "df['name_second_hero_class'].fillna('monoclass', inplace = True)\n",
    "df['id_second_hero_class'].fillna('monoclass', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boolean column for multiclass cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating column where 1 = multiclass, 0 = monoclass)\n",
    "# contains ' ' will suffice since only cards with a space in this value are multiclass\n",
    "df['is_multiclass'] = np.where((df.multiclassids.str.contains(' ')), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boolean column for cards with child ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating column where 1 = card has childids, 0 = card has no childids)\n",
    "# contains ',' will suffice since only cards with a comma in this value have childids\n",
    "df['has_child_ids'] = np.where((df.childids.str.contains(',')), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating boolean columns for rarity levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating through levels of rarity (common, rare, epic, etc)\n",
    "# creating boolean column for each\n",
    "for level in rarities.name:\n",
    "    df['is_' + level] = np.where((df.name_rarity == level), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1289 entries, 0 to 1288\n",
      "Data columns (total 78 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   multiclassids           1289 non-null   object \n",
      " 1   manacost                1289 non-null   int64  \n",
      " 2   name                    1289 non-null   object \n",
      " 3   text                    1289 non-null   object \n",
      " 4   in_duels                1289 non-null   int64  \n",
      " 5   health                  1289 non-null   float64\n",
      " 6   attack                  1289 non-null   float64\n",
      " 7   childids                1289 non-null   object \n",
      " 8   durability              1289 non-null   float64\n",
      " 9   armor                   1289 non-null   float64\n",
      " 10  id_prime_hero_class     1289 non-null   object \n",
      " 11  name_prime_hero_class   1289 non-null   object \n",
      " 12  id_rarity               1289 non-null   int64  \n",
      " 13  name_rarity             1289 non-null   object \n",
      " 14  id_set                  1289 non-null   int64  \n",
      " 15  name_set                1289 non-null   object \n",
      " 16  id_card_type            1289 non-null   int64  \n",
      " 17  name_card_type          1289 non-null   object \n",
      " 18  id_minion_tribe         1289 non-null   object \n",
      " 19  name_minion_tribe       1289 non-null   object \n",
      " 20  has_taunt               1289 non-null   int64  \n",
      " 21  has_spellpower          1289 non-null   int64  \n",
      " 22  has_divine-shield       1289 non-null   int64  \n",
      " 23  has_charge              1289 non-null   int64  \n",
      " 24  has_secret              1289 non-null   int64  \n",
      " 25  has_stealth             1289 non-null   int64  \n",
      " 26  has_battlecry           1289 non-null   int64  \n",
      " 27  has_freeze              1289 non-null   int64  \n",
      " 28  has_windfury            1289 non-null   int64  \n",
      " 29  has_deathrattle         1289 non-null   int64  \n",
      " 30  has_combo               1289 non-null   int64  \n",
      " 31  has_overload            1289 non-null   int64  \n",
      " 32  has_silence             1289 non-null   int64  \n",
      " 33  has_counter             1289 non-null   int64  \n",
      " 34  has_immune              1289 non-null   int64  \n",
      " 35  has_spare-part          1289 non-null   int64  \n",
      " 36  has_inspire             1289 non-null   int64  \n",
      " 37  has_discover            1289 non-null   int64  \n",
      " 38  has_quest               1289 non-null   int64  \n",
      " 39  has_poisonous           1289 non-null   int64  \n",
      " 40  has_adapt               1289 non-null   int64  \n",
      " 41  has_lifesteal           1289 non-null   int64  \n",
      " 42  has_recruit             1289 non-null   int64  \n",
      " 43  has_echo                1289 non-null   int64  \n",
      " 44  has_rush                1289 non-null   int64  \n",
      " 45  has_overkill            1289 non-null   int64  \n",
      " 46  has_modular             1289 non-null   int64  \n",
      " 47  has_evilzug             1289 non-null   int64  \n",
      " 48  has_twinspell           1289 non-null   int64  \n",
      " 49  has_mega-windfury       1289 non-null   int64  \n",
      " 50  has_reborn              1289 non-null   int64  \n",
      " 51  has_empower             1289 non-null   int64  \n",
      " 52  has_outcast             1289 non-null   int64  \n",
      " 53  has_spellburst          1289 non-null   int64  \n",
      " 54  has_sidequest           1289 non-null   int64  \n",
      " 55  has_corrupt             1289 non-null   int64  \n",
      " 56  has_start-of-combat     1289 non-null   int64  \n",
      " 57  has_start-of-game       1289 non-null   int64  \n",
      " 58  id_second_hero_class    1289 non-null   object \n",
      " 59  name_second_hero_class  1289 non-null   object \n",
      " 60  is_demonhunter          1289 non-null   int64  \n",
      " 61  is_druid                1289 non-null   int64  \n",
      " 62  is_hunter               1289 non-null   int64  \n",
      " 63  is_mage                 1289 non-null   int64  \n",
      " 64  is_paladin              1289 non-null   int64  \n",
      " 65  is_priest               1289 non-null   int64  \n",
      " 66  is_rogue                1289 non-null   int64  \n",
      " 67  is_shaman               1289 non-null   int64  \n",
      " 68  is_warlock              1289 non-null   int64  \n",
      " 69  is_warrior              1289 non-null   int64  \n",
      " 70  is_neutral              1289 non-null   int64  \n",
      " 71  is_multiclass           1289 non-null   int64  \n",
      " 72  has_child_ids           1289 non-null   int64  \n",
      " 73  is_common               1289 non-null   int64  \n",
      " 74  is_free                 1289 non-null   int64  \n",
      " 75  is_rare                 1289 non-null   int64  \n",
      " 76  is_epic                 1289 non-null   int64  \n",
      " 77  is_legendary            1289 non-null   int64  \n",
      "dtypes: float64(4), int64(61), object(13)\n",
      "memory usage: 795.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
